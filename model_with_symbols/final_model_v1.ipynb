{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '-', '=', 'division', 'multiplication', 'x', 'y', 'z']\n",
      "['test_purpose']\n"
     ]
    }
   ],
   "source": [
    "## Insert local drive location where all 5 signs are extracted\n",
    "import os\n",
    "\n",
    "def path_directory(path):\n",
    "    path_name = []\n",
    "    test_purpose = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename == \"test_purpose\":\n",
    "            test_purpose.append(\"test_purpose\")\n",
    "        else:\n",
    "            path_name.append(filename)\n",
    "        \n",
    "    return path_name,test_purpose\n",
    "\n",
    "\n",
    "path,test_purpose = path_directory('C:/Users/Vishal Patil/Desktop/Data Science/Sem 3/Deep Learning Neural Networks/Project/Data_symbols/extract_necessary')\n",
    "print(path)\n",
    "print(test_purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_symbols(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in path:\n",
    "        for img in glob.glob(\"C:/Users/Vishal Patil/Desktop/Data Science/Sem 3/Deep Learning Neural Networks/Project/Data_symbols/extract_necessary/{}/*.jpg\".format(path)):\n",
    "            #images.append(img)\n",
    "            labels.append(path)\n",
    "            #np.append(train_images,im_resize)\n",
    "            img = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "            im_resize = cv2.resize(img,(28,28), interpolation=cv2.INTER_AREA)\n",
    "            im_bw = cv2.bitwise_not(im_resize)\n",
    "            #dilated_image = cv2.dilate(im_resize, (3, 3))\n",
    "            im_resize=np.reshape(im_bw,(28,28))\n",
    "            images.append(im_resize)\n",
    "    \n",
    "    return images,labels\n",
    "\n",
    "images,labels = add_symbols(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30030\n",
      "(90030,)\n",
      "(90030, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "### dictionary to convert string classes to integer and concatenate the kaggle symbols dataset with mnist dataset\n",
    "\n",
    "dict1 = {10:'+',11:'-', 12:'=', 13:'division', 14:'multiplication', 15:'x', 16:'y', 17:'z'}\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    for j in dict1:\n",
    "        if labels[i] == dict1[j]:\n",
    "            labels[i] = j\n",
    "print(len(labels))\n",
    "labels_array = np.array(labels)\n",
    "train_labels = np.concatenate((train_labels,labels_array))\n",
    "symbols_array = np.array(images)\n",
    "train_images = np.concatenate((train_images,symbols_array))\n",
    "print(train_labels.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter an image number50000\n",
      "Label is 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAANeElEQVR4nO3df6hc9ZnH8c/HH8XEiEaDmqTRtDf+sctizBpkRVmqJcUVIVZwacAlGwOpUKHVVVayQkUpyLKtgn8oKQaza9dSE7tKVYyEsP6CYvyxGhsbf5CNSW4SomASVLrRZ/+4J8s1uec7N3Nm5szmeb/gMjPnmXPOw5BPzpn5npmvI0IAjn8ntN0AgMEg7EAShB1IgrADSRB2IImTBrkz23z0D/RZRHii5Y2O7Lavsv1H2+/bvqPJtgD0l7sdZ7d9oqStkhZJ2iHpVUlLIuIPhXU4sgN91o8j+yWS3o+IDyPiT5J+LWlxg+0B6KMmYZ8t6aNxj3dUy77G9grbm2xvarAvAA01+YBuolOFo07TI2KVpFUSp/FAm5oc2XdImjPu8Tcl7WrWDoB+aRL2VyVdYPtbtr8h6QeSnupNWwB6revT+Ig4ZPtmSc9JOlHS6oh4p2edAeiprofeutoZ79mBvuvLRTUA/v8g7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJgU7ZjO7Mnz+/WL/llltqayMjI8V1p06dWqyvXLmyWD/99NOL9Weffba2duDAgeK66C2O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBLO4DoFp06YV69u3by/WzzjjjF6201M7d+6srZWuD5CktWvX9rqdFOpmcW10UY3tbZIOSPpS0qGIWNhkewD6pxdX0F0REft6sB0AfcR7diCJpmEPSettv2Z7xURPsL3C9ibbmxruC0ADTU/jL4uIXbbPlvS87Xcj4oXxT4iIVZJWSXxAB7Sp0ZE9InZVt3sl/VbSJb1oCkDvdR1226faPu3wfUnfk7S5V40B6K2ux9ltf1tjR3Np7O3Av0fEzzqsw2n8BE477bRi/ZlnninWP/7449raG2+8UVx3wYIFxfr5559frM+ZM6dYnzJlSm1tz549xXUvvfTSYr3T+ln1fJw9Ij6UVP5VBQBDg6E3IAnCDiRB2IEkCDuQBGEHkuArrmhkxowZxfrtt9/eVU2Sli1bVqyvWbOmWM+qbuiNIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMGUzWhk377yb42+/PLLtbVO4+ydvn7LOPux4cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo5Gpk+fXqyvXLmy623PmjWr63VxNI7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEvxuPovnzyxP1Pv7448X6vHnzamtbt24trrto0aJi/aOPPirWs+r6d+Ntr7a91/bmccvOtP287feq2/KVFQBaN5nT+EckXXXEsjskbYiICyRtqB4DGGIdwx4RL0j65IjFiyUd/k2gNZKu7XFfAHqs22vjz4mIUUmKiFHbZ9c90fYKSSu63A+AHun7F2EiYpWkVRIf0AFt6nbobY/tmZJU3e7tXUsA+qHbsD8laWl1f6mkJ3vTDoB+6TjObvsxSd+RNEPSHkk/lfQfkn4j6TxJ2yVdHxFHfog30bY4jR8yS5cuLdbvvvvuYn3OnDnF+ueff15bu+aaa4rrbty4sVjHxOrG2Tu+Z4+IJTWl7zbqCMBAcbkskARhB5Ig7EAShB1IgrADSfBT0seBadOm1dZuu+224rp33nlnsX7CCeXjwSeflEdcL7/88trau+++W1wXvcWRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9OPDII4/U1q677rpG2167dm2xfv/99xfrjKUPD47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zHgZGRkb5t+8EHHyzWX3nllb7tG73FkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCc/Tiwfv362tr8+fP7tm2p8zj8vffeW1vbtWtXVz2hOx2P7LZX295re/O4ZXfZ3mn7zerv6v62CaCpyZzGPyLpqgmW3xcRF1V/z/S2LQC91jHsEfGCpPIcPwCGXpMP6G62/VZ1mj+97km2V9jeZHtTg30BaKjbsD8oaUTSRZJGJf287okRsSoiFkbEwi73BaAHugp7ROyJiC8j4itJv5R0SW/bAtBrXYXd9sxxD78vaXPdcwEMB0dE+Qn2Y5K+I2mGpD2Sflo9vkhSSNom6YcRMdpxZ3Z5Z+jKlClTamuPPvpocd2LL764WD/vvPO66umw3bt319aWLVtWXPe5555rtO+sIsITLe94UU1ELJlg8cONOwIwUFwuCyRB2IEkCDuQBGEHkiDsQBIdh956ujOG3gbulFNOKdZPOqk8ILN///5etvM1X3zxRbF+6623FusPPfRQL9s5btQNvXFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdH0YUXXlis33fffcX6FVdc0fW+t2/fXqzPnTu3620fzxhnB5Ij7EAShB1IgrADSRB2IAnCDiRB2IEkGGcfAlOnTi3WP/vsswF1cuymT6+d+UuStHr16tra4sWLG+179uzZxfroaMdfNz8uMc4OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0l0nMUVzY2MjBTrL730UrH+9NNPF+ubN2+urXUaa16+fHmxfvLJJxfrnca6582bV6yXfPDBB8V61nH0bnU8stueY3uj7S2237H942r5mbaft/1edVu+ugJAqyZzGn9I0j9ExJ9J+itJP7L955LukLQhIi6QtKF6DGBIdQx7RIxGxOvV/QOStkiaLWmxpDXV09ZIurZfTQJo7pjes9ueK2mBpN9LOiciRqWx/xBsn12zzgpJK5q1CaCpSYfd9jRJ6yT9JCL22xNea3+UiFglaVW1Db4IA7RkUkNvtk/WWNB/FRFPVIv32J5Z1WdK2tufFgH0Qscju8cO4Q9L2hIRvxhXekrSUkn3VrdP9qXD48D1119frJ977rnF+o033tjLdo5JpzO4Jl+RPnjwYLF+0003db1tHG0yp/GXSfo7SW/bfrNatlJjIf+N7eWStksq/4sG0KqOYY+IlyTV/ff+3d62A6BfuFwWSIKwA0kQdiAJwg4kQdiBJPiK6wCcddZZbbfQN+vWrSvW77nnntra3r3l67B2797dVU+YGEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCKZsHoNPPMV955ZXF+g033FCsz5o1q7b26aefFtft5IEHHijWX3zxxWL90KFDjfaPY8eUzUByhB1IgrADSRB2IAnCDiRB2IEkCDuQBOPswHGGcXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKJj2G3Psb3R9hbb79j+cbX8Lts7bb9Z/V3d/3YBdKvjRTW2Z0qaGRGv2z5N0muSrpX0t5IORsS/THpnXFQD9F3dRTWTmZ99VNJodf+A7S2SZve2PQD9dkzv2W3PlbRA0u+rRTfbfsv2atvTa9ZZYXuT7U2NOgXQyKSvjbc9TdJ/SvpZRDxh+xxJ+ySFpHs0dqp/Y4dtcBoP9Fndafykwm77ZEm/k/RcRPxigvpcSb+LiL/osB3CDvRZ11+EsW1JD0vaMj7o1Qd3h31f0uamTQLon8l8Gn+5pBclvS3pq2rxSklLJF2ksdP4bZJ+WH2YV9oWR3agzxqdxvcKYQf6j++zA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuj4g5M9tk/Sf497PKNaNoyGtbdh7Uuit271srfz6woD/T77UTu3N0XEwtYaKBjW3oa1L4neujWo3jiNB5Ig7EASbYd9Vcv7LxnW3oa1L4neujWQ3lp9zw5gcNo+sgMYEMIOJNFK2G1fZfuPtt+3fUcbPdSxvc3229U01K3OT1fNobfX9uZxy860/bzt96rbCefYa6m3oZjGuzDNeKuvXdvTnw/8PbvtEyVtlbRI0g5Jr0paEhF/GGgjNWxvk7QwIlq/AMP2X0s6KOlfD0+tZfufJX0SEfdW/1FOj4h/HJLe7tIxTuPdp97qphn/e7X42vVy+vNutHFkv0TS+xHxYUT8SdKvJS1uoY+hFxEvSPrkiMWLJa2p7q/R2D+WgavpbShExGhEvF7dPyDp8DTjrb52hb4Goo2wz5b00bjHOzRc872HpPW2X7O9ou1mJnDO4Wm2qtuzW+7nSB2n8R6kI6YZH5rXrpvpz5tqI+wTTU0zTON/l0XEX0r6G0k/qk5XMTkPShrR2ByAo5J+3mYz1TTj6yT9JCL2t9nLeBP0NZDXrY2w75A0Z9zjb0ra1UIfE4qIXdXtXkm/1djbjmGy5/AMutXt3pb7+T8RsScivoyIryT9Ui2+dtU04+sk/SoinqgWt/7aTdTXoF63NsL+qqQLbH/L9jck/UDSUy30cRTbp1YfnMj2qZK+p+GbivopSUur+0slPdliL18zLNN4100zrpZfu9anP4+Igf9Julpjn8h/IOmf2uihpq9vS/qv6u+dtnuT9JjGTuv+R2NnRMslnSVpg6T3qtszh6i3f9PY1N5vaSxYM1vq7XKNvTV8S9Kb1d/Vbb92hb4G8rpxuSyQBFfQAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/wvwpj8O76pvCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_image = int(input(\"Please enter an image number\"))\n",
    "for i in dict1:\n",
    "    example = train_images[input_image]\n",
    "    if i == train_labels[input_image]:\n",
    "        print(\"label is\",dict1[i])\n",
    "        break\n",
    "    else: \n",
    "        print(\"Label is\",train_labels[input_image])\n",
    "        break\n",
    "plt.imshow(example.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "#example = train_images[61000]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (90030, 28, 28)\n",
      "Shape of y_train: (90030,)\n",
      "Shape of X_test: (10000, 28, 28)\n",
      "Shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Shape of X_train: {}\".format(train_images.shape))\n",
    "print (\"Shape of y_train: {}\".format(train_labels.shape))\n",
    "print (\"Shape of X_test: {}\".format(test_images.shape))\n",
    "print (\"Shape of y_test: {}\".format(test_labels.shape))\n",
    "\n",
    "train_images = train_images.reshape(90030, 28, 28, 1)\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                663570    \n",
      "=================================================================\n",
      "Total params: 682,386\n",
      "Trainable params: 682,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(18, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 18)                663570    \n",
      "=================================================================\n",
      "Total params: 682,386\n",
      "Trainable params: 682,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "2814/2814 [==============================] - 229s 81ms/step - loss: 0.1344 - accuracy: 0.9616\n",
      "Epoch 2/2\n",
      "2814/2814 [==============================] - 227s 81ms/step - loss: 0.0423 - accuracy: 0.9879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3bc580ca48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=create_model()\n",
    "model.fit(train_images, train_labels, epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_symbols(test_purpose):\n",
    "    testing_images = []\n",
    "    for path in test_purpose:\n",
    "        for img in glob.glob(\"C:/Users/Vishal Patil/Desktop/Data Science/Sem 3/Deep Learning Neural Networks/Project/Data_symbols/extract_necessary/{}/*.jpg\".format(path)):\n",
    "            equalto = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "            gray = cv2.cvtColor(equalto, cv2.COLOR_BGR2GRAY)\n",
    "            im_resize = cv2.resize(gray,(28,28), interpolation=cv2.INTER_AREA)\n",
    "            changed_colour = cv2.bitwise_not(im_resize)\n",
    "            changed_colour = np.reshape(changed_colour,(28,28))\n",
    "            #images.append(changed_colour)\n",
    "            testing_images.append(changed_colour)\n",
    "            #np.append(train_images,im_resize)\n",
    "    return testing_images\n",
    "\n",
    "test_symbols = add_symbols(test_purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is -\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is =\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def initial_predict(example):\n",
    "    prediction = model.predict_classes(example.reshape(1, 28, 28, 1))\n",
    "    if prediction[0] >= 9:\n",
    "        for i in dict1:\n",
    "            if i == prediction[0]:\n",
    "                print(\"Predicted class is\", dict1[i])\n",
    "    else:\n",
    "        print(\"Predicted class is\", prediction)\n",
    "    plt.imshow(example.reshape(28, 28), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    return prediction\n",
    "init = initial_predict(test_images[25])\n",
    "predict_symbols = initial_predict(test_symbols[0])\n",
    "predict_symbols = initial_predict(test_symbols[2])\n",
    "#dict1 = {10:'+',11:'-', 12:'=', 13:'division', 14:'multiplication', 15:'x', 16:'y', 17:'z'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3528e9088>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Final - Final\n",
    "\n",
    "def cropping(path):\n",
    "    print('i am here')\n",
    "    imagem = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # Convert black pixels to white and white to black\n",
    "    img = cv2.bitwise_not(imagem)\n",
    "    # Convert to gray-scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Blur the image to reduce noise\n",
    "    img_blur = cv2.medianBlur(gray, 5)\n",
    "    # Find the edges in the image using canny detector\n",
    "    edges = cv2.Canny(img_blur, 50, 200)\n",
    "    # Detect points that form a line\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180,\n",
    "                            threshold=100, minLineLength=10, maxLineGap=250)\n",
    "    # Draw lines on the image\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 0, 0), 1)\n",
    "    cropped = []\n",
    "    # Apply hough transform on the image\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1,\n",
    "                               img.shape[0]/64, param1=200, param2=10, minRadius=10, maxRadius=20)\n",
    "    # Draw detected circles\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        sorted_array = circles[0][np.argsort(circles[0][:, 1])]\n",
    "        for i in sorted_array:\n",
    "            # Draw outer circle\n",
    "            cv2.circle(img, (i[0], i[1]), i[2], (0, 0, 0), 10)\n",
    "            crop_img = img[i[1] - i[2]:i[1] + i[2], i[0] - i[2]:i[0] + i[2], :]\n",
    "            cropped.append(crop_img)\n",
    "    return cropped\n",
    "\n",
    "### Give location of image\n",
    "cropped_image = cropping('C:/Users/Vishal Patil/Desktop/Data Science/Sem 3/Deep Learning Neural Networks/Project/deep-homework-grader-main/data/homework/train/00059.jpg')\n",
    "\n",
    "plt.imshow(cropped_image[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is [9]\n",
      "Predicted class is [0]\n",
      "Predicted class is [3]\n",
      "Predicted class is [6]\n"
     ]
    }
   ],
   "source": [
    "def predict(images):\n",
    "    digits_stored = []\n",
    "    signs = []\n",
    "    for i in images:\n",
    "        im_gray = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "        #(thresh, im_bw) = cv2.threshold(im_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        thresh = 127\n",
    "        im_bw = cv2.threshold(im_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        dim = (28, 28)\n",
    "        resized = cv2.resize(im_bw, dim)\n",
    "        # print(resized.shape)\n",
    "        imge = np.resize(resized, (28, 28, 1))\n",
    "        arr = np.array(imge) / 255\n",
    "        im2arr = arr.reshape(1, 28, 28, 1)\n",
    "        y_pred = model.predict_classes(im2arr)\n",
    "        if y_pred > 9:\n",
    "            for j in dict1:\n",
    "                if y_pred == j:\n",
    "                    signs.append(dict1[j])\n",
    "        digits_stored.append(y_pred)\n",
    "        print(\"Predicted class is\", y_pred)\n",
    "\n",
    "    return digits_stored,signs\n",
    "\n",
    "image_prediction,signs = predict(cropped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer is incorrect for question 1 and Your answer is [9] ,Expected answer is [5]\n",
      "Your answer is incorrect for question 2 and Your answer is [0] ,Expected answer is [3]\n",
      "Your answer is incorrect for question 3 and Your answer is [3] ,Expected answer is [0]\n",
      "Your answer is correct for question 4 ,Your answer is [6]\n",
      "Total marks = 1\n"
     ]
    }
   ],
   "source": [
    "## Matching with existing answer sheet\n",
    "\n",
    "def matching(image_prediction,standard_array):\n",
    "    total_marks = 0\n",
    "    #unmatched = []\n",
    "    for i in range(len(standard_array)):\n",
    "        if standard_array[i] == image_prediction[i]:\n",
    "            print(\"Your answer is correct for question\",i+1,\",Your answer is\",image_prediction[i])\n",
    "            total_marks = total_marks + 1\n",
    "        else:\n",
    "            print(\"Your answer is incorrect for question\",i+1,\"and Your answer is\",image_prediction[i],\",Expected answer is\",standard_array[i])\n",
    "            \n",
    "    return total_marks\n",
    "\n",
    "### Define standard array which contains answers\n",
    "standard_array = np.array([[5], [3], [0], [6]])\n",
    "#np.where(standard_array==image_prediction)\n",
    "#np.intersect1d(image_prediction,standard_array)\n",
    "match = matching(image_prediction,standard_array)   \n",
    "print(\"Total marks =\",match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "\n",
    "#model.save('C:/Users/Vishal Patil/Desktop/Data Science/Sem 3/Deep Learning Neural Networks/Project/model_with_symbols/most_accurate.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Partial credits\n",
    "\n",
    "maxArea = 800\n",
    "minArea = 100\n",
    "\n",
    "for fin in fin_crop:\n",
    "    image = np.array(fin)#, dtype = np.uint8)\n",
    "    #gray = image[:, :, ::-1].copy().astype(np.uint8)\n",
    "    Igray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    # Igray = gray\n",
    "\n",
    "    # Threshold\n",
    "    #ret, Ithresh = cv2.threshold(Igray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    ret, Ithresh = cv2.threshold(Igray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    # Keep only small components but not to small\n",
    "    comp = cv2.connectedComponentsWithStats(Ithresh)\n",
    "\n",
    "    labels = comp[1]\n",
    "    labelStats = comp[2]\n",
    "    labelAreas = labelStats[:,4]\n",
    "\n",
    "    for compLabel in range(1,comp[0],1):\n",
    "        print(labelAreas[compLabel])\n",
    "\n",
    "        if labelAreas[compLabel] > maxArea or labelAreas[compLabel] < minArea:\n",
    "            labels[labels==compLabel] = 0\n",
    "\n",
    "    labels[labels>0] =  1\n",
    "\n",
    "    # Do dilation\n",
    "    se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(25,25))\n",
    "    IdilateText = cv2.morphologyEx(labels.astype(np.uint8),cv2.MORPH_DILATE,se)\n",
    "\n",
    "    # Find connected component again\n",
    "    comp = cv2.connectedComponentsWithStats(IdilateText)\n",
    "\n",
    "    # Draw a rectangle around the text\n",
    "    labels = comp[1]\n",
    "    labelStats = comp[2]\n",
    "\n",
    "    for compLabel in range(1,comp[0],1):\n",
    "        print('i am here')\n",
    "        cv2.rectangle(Igray,(labelStats[compLabel,0],labelStats[compLabel,1]),(labelStats[compLabel,0]+labelStats[compLabel,2],labelStats[compLabel,1]+labelStats[compLabel,3]),(0,0,255),2)\n",
    "    plt.imshow(Igray)\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
